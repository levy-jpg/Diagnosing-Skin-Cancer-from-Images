digraph {
	graph [size="59.55,59.55"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1872105256576 [label="
 (1, 7)" fillcolor=darkolivegreen1]
	1870839720640 [label=AddmmBackward0]
	1870839721360 -> 1870839720640
	1870816110768 [label="fc.bias
 (7)" fillcolor=lightblue]
	1870816110768 -> 1870839721360
	1870839721360 [label=AccumulateGrad]
	1870839721600 -> 1870839720640
	1870839721600 [label=ViewBackward0]
	1870839721552 -> 1870839721600
	1870839721552 [label=MeanBackward1]
	1870839721312 -> 1870839721552
	1870839721312 [label=ReluBackward0]
	1870839721216 -> 1870839721312
	1870839721216 [label=AddBackward0]
	1870839721120 -> 1870839721216
	1870839721120 [label=NativeBatchNormBackward0]
	1870839720976 -> 1870839721120
	1870839720976 [label=ConvolutionBackward0]
	1870839720784 -> 1870839720976
	1870839720784 [label=ReluBackward0]
	1870839720496 -> 1870839720784
	1870839720496 [label=NativeBatchNormBackward0]
	1870839720400 -> 1870839720496
	1870839720400 [label=ConvolutionBackward0]
	1870839721168 -> 1870839720400
	1870839721168 [label=ReluBackward0]
	1870839720016 -> 1870839721168
	1870839720016 [label=AddBackward0]
	1870839719920 -> 1870839720016
	1870839719920 [label=NativeBatchNormBackward0]
	1870839719728 -> 1870839719920
	1870839719728 [label=ConvolutionBackward0]
	1870839721840 -> 1870839719728
	1870839721840 [label=ReluBackward0]
	1870839721936 -> 1870839721840
	1870839721936 [label=NativeBatchNormBackward0]
	1870839759008 -> 1870839721936
	1870839759008 [label=ConvolutionBackward0]
	1870839759200 -> 1870839759008
	1870839759200 [label=ReluBackward0]
	1870839759344 -> 1870839759200
	1870839759344 [label=AddBackward0]
	1870839759440 -> 1870839759344
	1870839759440 [label=NativeBatchNormBackward0]
	1870839759584 -> 1870839759440
	1870839759584 [label=ConvolutionBackward0]
	1870839759776 -> 1870839759584
	1870839759776 [label=ReluBackward0]
	1870839759920 -> 1870839759776
	1870839759920 [label=NativeBatchNormBackward0]
	1870839760016 -> 1870839759920
	1870839760016 [label=ConvolutionBackward0]
	1870839759392 -> 1870839760016
	1870839759392 [label=ReluBackward0]
	1870839760304 -> 1870839759392
	1870839760304 [label=AddBackward0]
	1870839760400 -> 1870839760304
	1870839760400 [label=NativeBatchNormBackward0]
	1870839760544 -> 1870839760400
	1870839760544 [label=ConvolutionBackward0]
	1870839760736 -> 1870839760544
	1870839760736 [label=ReluBackward0]
	1870839760880 -> 1870839760736
	1870839760880 [label=NativeBatchNormBackward0]
	1870839760976 -> 1870839760880
	1870839760976 [label=ConvolutionBackward0]
	1870839761168 -> 1870839760976
	1870839761168 [label=ReluBackward0]
	1870839761312 -> 1870839761168
	1870839761312 [label=AddBackward0]
	1870839761408 -> 1870839761312
	1870839761408 [label=NativeBatchNormBackward0]
	1870839761552 -> 1870839761408
	1870839761552 [label=ConvolutionBackward0]
	1870839761744 -> 1870839761552
	1870839761744 [label=ReluBackward0]
	1870839761888 -> 1870839761744
	1870839761888 [label=NativeBatchNormBackward0]
	1870839761984 -> 1870839761888
	1870839761984 [label=ConvolutionBackward0]
	1870839761360 -> 1870839761984
	1870839761360 [label=ReluBackward0]
	1870839762272 -> 1870839761360
	1870839762272 [label=AddBackward0]
	1870839762368 -> 1870839762272
	1870839762368 [label=NativeBatchNormBackward0]
	1870839762512 -> 1870839762368
	1870839762512 [label=ConvolutionBackward0]
	1870839762704 -> 1870839762512
	1870839762704 [label=ReluBackward0]
	1870839762848 -> 1870839762704
	1870839762848 [label=NativeBatchNormBackward0]
	1870839762896 -> 1870839762848
	1870839762896 [label=ConvolutionBackward0]
	1870839705856 -> 1870839762896
	1870839705856 [label=ReluBackward0]
	1870839706000 -> 1870839705856
	1870839706000 [label=AddBackward0]
	1870839706096 -> 1870839706000
	1870839706096 [label=NativeBatchNormBackward0]
	1870839706240 -> 1870839706096
	1870839706240 [label=ConvolutionBackward0]
	1870839706432 -> 1870839706240
	1870839706432 [label=ReluBackward0]
	1870839706576 -> 1870839706432
	1870839706576 [label=NativeBatchNormBackward0]
	1870839706672 -> 1870839706576
	1870839706672 [label=ConvolutionBackward0]
	1870839706048 -> 1870839706672
	1870839706048 [label=ReluBackward0]
	1870839706960 -> 1870839706048
	1870839706960 [label=AddBackward0]
	1870839707056 -> 1870839706960
	1870839707056 [label=NativeBatchNormBackward0]
	1870839707200 -> 1870839707056
	1870839707200 [label=ConvolutionBackward0]
	1870839707392 -> 1870839707200
	1870839707392 [label=ReluBackward0]
	1870839707536 -> 1870839707392
	1870839707536 [label=NativeBatchNormBackward0]
	1870839707632 -> 1870839707536
	1870839707632 [label=ConvolutionBackward0]
	1870839707008 -> 1870839707632
	1870839707008 [label=MaxPool2DWithIndicesBackward0]
	1870839707920 -> 1870839707008
	1870839707920 [label=ReluBackward0]
	1870839708016 -> 1870839707920
	1870839708016 [label=NativeBatchNormBackward0]
	1870839708112 -> 1870839708016
	1870839708112 [label=ConvolutionBackward0]
	1870839708304 -> 1870839708112
	1870764322224 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	1870764322224 -> 1870839708304
	1870839708304 [label=AccumulateGrad]
	1870839708064 -> 1870839708016
	1870764679712 [label="bn1.weight
 (64)" fillcolor=lightblue]
	1870764679712 -> 1870839708064
	1870839708064 [label=AccumulateGrad]
	1870839707728 -> 1870839708016
	1870764320224 [label="bn1.bias
 (64)" fillcolor=lightblue]
	1870764320224 -> 1870839707728
	1870839707728 [label=AccumulateGrad]
	1870839707824 -> 1870839707632
	1870815894080 [label="layer1.0.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1870815894080 -> 1870839707824
	1870839707824 [label=AccumulateGrad]
	1870839707584 -> 1870839707536
	1870764679312 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	1870764679312 -> 1870839707584
	1870839707584 [label=AccumulateGrad]
	1870839707440 -> 1870839707536
	1870815893760 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	1870815893760 -> 1870839707440
	1870839707440 [label=AccumulateGrad]
	1870839707344 -> 1870839707200
	1870817398592 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1870817398592 -> 1870839707344
	1870839707344 [label=AccumulateGrad]
	1870839707152 -> 1870839707056
	1870534363792 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	1870534363792 -> 1870839707152
	1870839707152 [label=AccumulateGrad]
	1870839707104 -> 1870839707056
	1870817398512 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	1870817398512 -> 1870839707104
	1870839707104 [label=AccumulateGrad]
	1870839707008 -> 1870839706960
	1870839706864 -> 1870839706672
	1870817398272 [label="layer1.1.conv1.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1870817398272 -> 1870839706864
	1870839706864 [label=AccumulateGrad]
	1870839706624 -> 1870839706576
	1870817397952 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	1870817397952 -> 1870839706624
	1870839706624 [label=AccumulateGrad]
	1870839706480 -> 1870839706576
	1870817398192 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	1870817398192 -> 1870839706480
	1870839706480 [label=AccumulateGrad]
	1870839706384 -> 1870839706240
	1870817386720 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1870817386720 -> 1870839706384
	1870839706384 [label=AccumulateGrad]
	1870839706192 -> 1870839706096
	1870817390400 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	1870817390400 -> 1870839706192
	1870839706192 [label=AccumulateGrad]
	1870839706144 -> 1870839706096
	1870817386880 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	1870817386880 -> 1870839706144
	1870839706144 [label=AccumulateGrad]
	1870839706048 -> 1870839706000
	1870839705808 -> 1870839762896
	1870817390320 [label="layer2.0.conv1.weight
 (128, 64, 3, 3)" fillcolor=lightblue]
	1870817390320 -> 1870839705808
	1870839705808 [label=AccumulateGrad]
	1870839762752 -> 1870839762848
	1870817389760 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	1870817389760 -> 1870839762752
	1870839762752 [label=AccumulateGrad]
	1870839705664 -> 1870839762848
	1870817382864 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	1870817382864 -> 1870839705664
	1870839705664 [label=AccumulateGrad]
	1870839762656 -> 1870839762512
	1870817383744 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1870817383744 -> 1870839762656
	1870839762656 [label=AccumulateGrad]
	1870839762464 -> 1870839762368
	1870764680432 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	1870764680432 -> 1870839762464
	1870839762464 [label=AccumulateGrad]
	1870839762416 -> 1870839762368
	1870545176352 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	1870545176352 -> 1870839762416
	1870839762416 [label=AccumulateGrad]
	1870839762320 -> 1870839762272
	1870839762320 [label=NativeBatchNormBackward0]
	1870839762800 -> 1870839762320
	1870839762800 [label=ConvolutionBackward0]
	1870839705856 -> 1870839762800
	1870839705904 -> 1870839762800
	1870817387600 [label="layer2.0.downsample.0.weight
 (128, 64, 1, 1)" fillcolor=lightblue]
	1870817387600 -> 1870839705904
	1870839705904 [label=AccumulateGrad]
	1870839762608 -> 1870839762320
	1870817387360 [label="layer2.0.downsample.1.weight
 (128)" fillcolor=lightblue]
	1870817387360 -> 1870839762608
	1870839762608 [label=AccumulateGrad]
	1870839762560 -> 1870839762320
	1870817388720 [label="layer2.0.downsample.1.bias
 (128)" fillcolor=lightblue]
	1870817388720 -> 1870839762560
	1870839762560 [label=AccumulateGrad]
	1870839762176 -> 1870839761984
	1870817384064 [label="layer2.1.conv1.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1870817384064 -> 1870839762176
	1870839762176 [label=AccumulateGrad]
	1870839761936 -> 1870839761888
	1870817383984 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	1870817383984 -> 1870839761936
	1870839761936 [label=AccumulateGrad]
	1870839761792 -> 1870839761888
	1870817384704 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	1870817384704 -> 1870839761792
	1870839761792 [label=AccumulateGrad]
	1870839761696 -> 1870839761552
	1870817386144 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1870817386144 -> 1870839761696
	1870839761696 [label=AccumulateGrad]
	1870839761504 -> 1870839761408
	1870817386064 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	1870817386064 -> 1870839761504
	1870839761504 [label=AccumulateGrad]
	1870839761456 -> 1870839761408
	1870817386304 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	1870817386304 -> 1870839761456
	1870839761456 [label=AccumulateGrad]
	1870839761360 -> 1870839761312
	1870839761120 -> 1870839760976
	1870817384384 [label="layer3.0.conv1.weight
 (256, 128, 3, 3)" fillcolor=lightblue]
	1870817384384 -> 1870839761120
	1870839761120 [label=AccumulateGrad]
	1870839760928 -> 1870839760880
	1870817384304 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	1870817384304 -> 1870839760928
	1870839760928 [label=AccumulateGrad]
	1870839760784 -> 1870839760880
	1870817384464 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	1870817384464 -> 1870839760784
	1870839760784 [label=AccumulateGrad]
	1870839760688 -> 1870839760544
	1870817383184 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1870817383184 -> 1870839760688
	1870839760688 [label=AccumulateGrad]
	1870839760496 -> 1870839760400
	1870817384544 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	1870817384544 -> 1870839760496
	1870839760496 [label=AccumulateGrad]
	1870839760448 -> 1870839760400
	1870817383264 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	1870817383264 -> 1870839760448
	1870839760448 [label=AccumulateGrad]
	1870839760352 -> 1870839760304
	1870839760352 [label=NativeBatchNormBackward0]
	1870839761072 -> 1870839760352
	1870839761072 [label=ConvolutionBackward0]
	1870839761168 -> 1870839761072
	1870839761216 -> 1870839761072
	1870817384864 [label="layer3.0.downsample.0.weight
 (256, 128, 1, 1)" fillcolor=lightblue]
	1870817384864 -> 1870839761216
	1870839761216 [label=AccumulateGrad]
	1870839760640 -> 1870839760352
	1870817384944 [label="layer3.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	1870817384944 -> 1870839760640
	1870839760640 [label=AccumulateGrad]
	1870839760592 -> 1870839760352
	1870817385024 [label="layer3.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	1870817385024 -> 1870839760592
	1870839760592 [label=AccumulateGrad]
	1870839760208 -> 1870839760016
	1870817382944 [label="layer3.1.conv1.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1870817382944 -> 1870839760208
	1870839760208 [label=AccumulateGrad]
	1870839759968 -> 1870839759920
	1870817382624 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	1870817382624 -> 1870839759968
	1870839759968 [label=AccumulateGrad]
	1870839759824 -> 1870839759920
	1870817383024 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	1870817383024 -> 1870839759824
	1870839759824 [label=AccumulateGrad]
	1870839759728 -> 1870839759584
	1870817331776 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1870817331776 -> 1870839759728
	1870839759728 [label=AccumulateGrad]
	1870839759536 -> 1870839759440
	1870817331616 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	1870817331616 -> 1870839759536
	1870839759536 [label=AccumulateGrad]
	1870839759488 -> 1870839759440
	1870817331296 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	1870817331296 -> 1870839759488
	1870839759488 [label=AccumulateGrad]
	1870839759392 -> 1870839759344
	1870839759152 -> 1870839759008
	1870817329856 [label="layer4.0.conv1.weight
 (512, 256, 3, 3)" fillcolor=lightblue]
	1870817329856 -> 1870839759152
	1870839759152 [label=AccumulateGrad]
	1870839758960 -> 1870839721936
	1870817329776 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	1870817329776 -> 1870839758960
	1870839758960 [label=AccumulateGrad]
	1870839758912 -> 1870839721936
	1870817330576 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	1870817330576 -> 1870839758912
	1870839758912 [label=AccumulateGrad]
	1870839721792 -> 1870839719728
	1870817324784 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1870817324784 -> 1870839721792
	1870839721792 [label=AccumulateGrad]
	1870839719776 -> 1870839719920
	1870817323904 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	1870817323904 -> 1870839719776
	1870839719776 [label=AccumulateGrad]
	1870839719824 -> 1870839719920
	1870817323984 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	1870817323984 -> 1870839719824
	1870839719824 [label=AccumulateGrad]
	1870839719968 -> 1870839720016
	1870839719968 [label=NativeBatchNormBackward0]
	1870839721888 -> 1870839719968
	1870839721888 [label=ConvolutionBackward0]
	1870839759200 -> 1870839721888
	1870839759248 -> 1870839721888
	1870817332176 [label="layer4.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	1870817332176 -> 1870839759248
	1870839759248 [label=AccumulateGrad]
	1870839721744 -> 1870839719968
	1870817330496 [label="layer4.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	1870817330496 -> 1870839721744
	1870839721744 [label=AccumulateGrad]
	1870839721696 -> 1870839719968
	1870817330656 [label="layer4.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	1870817330656 -> 1870839721696
	1870839721696 [label=AccumulateGrad]
	1870839720208 -> 1870839720400
	1870817323824 [label="layer4.1.conv1.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1870817323824 -> 1870839720208
	1870839720208 [label=AccumulateGrad]
	1870839720448 -> 1870839720496
	1870817323424 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	1870817323424 -> 1870839720448
	1870839720448 [label=AccumulateGrad]
	1870839720736 -> 1870839720496
	1870817323584 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	1870817323584 -> 1870839720736
	1870839720736 [label=AccumulateGrad]
	1870839720832 -> 1870839720976
	1870817313552 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1870817313552 -> 1870839720832
	1870839720832 [label=AccumulateGrad]
	1870839721024 -> 1870839721120
	1870817323024 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	1870817323024 -> 1870839721024
	1870839721024 [label=AccumulateGrad]
	1870839721072 -> 1870839721120
	1870817316272 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	1870817316272 -> 1870839721072
	1870839721072 [label=AccumulateGrad]
	1870839721168 -> 1870839721216
	1870839721648 -> 1870839720640
	1870839721648 [label=TBackward0]
	1870839721264 -> 1870839721648
	1870816112208 [label="fc.weight
 (7, 512)" fillcolor=lightblue]
	1870816112208 -> 1870839721264
	1870839721264 [label=AccumulateGrad]
	1870839720640 -> 1872105256576
}
